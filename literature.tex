\section{Literature reviews}
% Introduction to patent:
% Patent has a lot of information about innovation, represents the inventive progress of social.
% A good source to study about change and trend in science and technology.
% General research
% Study patent citation to learn about multiple linkage between inventors, organization, firms, etc.
% Economic: relating patent counts to industry & Compustat firms
% Find all distinct inventors and disambiguate them.
% Extract and format patent XML data

\subsection{United States Patent research}

\paragraph{US patent} United States patent database has become widely accessible to researchers and public since the early 1990s. The rich information included in the database cover almost all patents filed in the US in the last four decades. Each patent contains various information about an innovation, together all of them represent the inventive progress of technology and science not only in the US but also around the world~\footnote{In the late 1990s, around 45\% of US patents are awarded to foreign inventors.}. More specially, each patent is highly detailed to cover every
aspect of the invention, enabling us to study the progress from different angles. For example, information included in a patent contains the its belonging technological area, the inventors, the assignee,  terms of fields, types of inventors, citation to another patents, etc.
The database is also a good source to for investigating the change and trend in innovative activity over a particular period of time. 


\paragraph{US patent research analysis} Early research in US patent data goes
back at least to the 1960s when many researchers used patent data in economics
analysis and technology change. For example, in 1966,  Schmookler relates
industries to patent counts~\cite{Schmookler1966}, or in 1982, Griliches
addressed the problem of matching patents to Compustat
firms~\cite{Griliches1982}. The common approach of the early research is that
the rely heavily on the patent counts to come up with some indicative insight.
The simple patent count matrix does not allow them to faithfully capture more
aspects of the information included in each patent and the relation between
patents~\cite{Griliches1987}.

In another line of research, often researchers consider the patent database as
an ``inventor network", in which nodes are inventor or patent, while an edge
represents a citation between patents or a collaboration between two inventors.
Studying this network reveals multiple linkage between inventors,
organizations, firms, regions, etc. In~\cite{Hall01thenber}, Hall~\etal
initiated this line of research by pointing out and addressing several issues
while analysing citation data. They indicated that, due to the drastic change
in the rate of patenting, it is quite challenging to study the {\em received}
citation data of even a small set of patents. The problem is that to collect
all received citations of a particular patent {\em P} granted in year {\em t},
one has to visit all patents granted from year {\em t}. Hall~\etal also propose
two possible approaches to eliminate the problem, we refer the interested
reader to their paper. Using their proposed approaches, they show the main
trends in US patenting activity over three decades by different means of
measurement and across several main technology categories. Many later works
follow Hall~\etal's direction to study different problems in patent
analysing~\cite{Leskovec:2005, Hall2000, leskovec2007graph, Acs2002}.

\paragraph{Extracting and formating data in patent} A general technical problem
when doing patent analysis is how to extract and format data from patent
database. Typically, the data is available in Extensible Markup Language (XML)
format. However, since the patent is often objectively prepared by individual,
thus there is no consistent convention in naming, data field, etc throughout
the data set, thus limiting potential statistical and analytical analysis. For example, if the first student in this report files a patent, her name can be listed as Shruti Tople, or Shruti T., or even Shruti Tople Shrikant, etc. Researchers when processing the data must be aware of these inconsistency and deficiencies to generate a precise and comprehensive results. Recent work has addressed this problem by building a parser which will take account of relevant information into identifying name and/or organization~\cite{formattingpatentdata, disambiguation, Torvik:2009}.
% 
\subsection{Shortest path problem}
Given a graph $G = (V, E)$, we study the problem of finding the shortest path between a source node $u \in V$ and a destination node $v \in V$. In normal graph, the length of a path is the total of nodes along that path. However, in weighted graph where each edge $e_i = (u, v)$ has a weight $w_i$, the length of a path is computed as the total weigh of all edges in the path. For simplicity, we consider the normal graph as the weighted one with all $w_i=1$.

\paragraph{Shortest path from a given vertex} If the source node $u$ is fixed, there exist two popular algorithm to find the shortest path from $u$ to any $v$.
	\begin{itemize}
		\item {\bf Dijkstra algorithm} works only for the graph of non-negative edges. The general idea of Dijkstra algorithm is to find the nearest unvisted node to $u$, namely $k$, at every iteration. After that, the distances of $k$'s neighbors to $u$ are updated based on the distance of $k$ to $u$ and $k$ to that node. The time complexity of the algorithm without/with a min-priority queue are $O(|V|^2)$ and  $O(|E|+|V|\log|V|)$ respectively (where $|V|$ is the number of nodes, $|E|$ is the number of edges).

		One simple trick to make Dijkstra algorithm work with graph having negative edge is as following. Call $w_n < 0$ is the smallest negative weight of an edge in the graph, we add $|w_n|$ to every edge in $G$ to make it a non-negative edge graph $G'$. After that we run Dijkstra algorithm normally on $G'$ and deduct $|w_n|$ from all the edge in the result shortest path to get the correct answer.

		\item {\bf Bellman-ford algorithm} runs slower than Dijkstra algorithm, however it works with graphs having edges of arbitrary weight~\footnote{Note that it is not practical to find a shortest path in a graph having a negative circle.}. The algorithm can also detect the negative circle in the graph. The main insight of Bellman-ford algorithm can be explained in the context of dynamic programing. 		
		The key observation is that any shortest path from $u$ to $v$ in $G$ will have at most $|V|âˆ’1$ edges. Thus, we answer the question by sequentially looking for shortest path between $u$ and $v$ which has at most $1, 2, ..., |V|-1$ edges. The algorithm runs in  $O(|V|\cdot |E|)$ time, where $|V|$ and $|E|$ are the number of vertices and edges respectively.
	\end{itemize}

\paragraph{Shortest path between any pair of vertices}
The problem of shortest path between any pair of vertices can be easily solved by running $|V|$ times the above problem of shortest path from a given vertex. The best complexity of such approach is by using Dijkstra algorithm with min-priority queue ($O(|V|\cdot|E|+|V|^2\log|V|)$). We will discuss the other alternatives to address the problem in this section.
	\begin{itemize}	
		\item {\bf Floyd-Warshall algorithm} runs in $O(|V|^3)$. The psudo-code is illustrated in Algorithm~\ref{alg:floyd-war}. They key idea is to improve the estimate distance between $u$ and $v$ by visiting all the nodes and see if the node is in the shortest path between $u$ and $v$.

	 	\item {\bf Johnson algorithm} is more efficient than Floyd-Warshall algorithm when the graph is sparse ($|E| \ll |V|^2$). The algorithm runs in $O(V2log V + VE)$ time. Interested reader can find more details in~\cite{johnson-alg}.
	\end{itemize}

\begin{algorithm}
	\begin{algorithmic}[1]		
		\ForAll{$v \in V$} 
		   \State $dist[v][v] \gets 0$	\Comment{$dist$ is a $|V| \times |V|$ array of minimum distances initialized to infinity}
		\EndFor
		\ForAll{edge $(u,v) \in E$}
		   \State $dist[u][v] \gets w(u,v)$  \Comment{the weight of the edge $(u,v)$}
		\EndFor
		\ForAll{$1 \leq k \leq |V|$}
		    \ForAll{$1 \leq i \leq |V|$}
		      \ForAll{$1 \leq j \leq |V|$}
		         \If {$dist[i][j] > dist[i][k] + dist[k][j]$} 
		            \State $dist[i][j]\gets  dist[i][k] + dist[k][j]$
		        \EndIf
		      \EndFor
		    \EndFor
		\EndFor
	\end{algorithmic}
\caption{Floyd-Warshall algorithm, cited from~\cite{floyd-war-wiki}}
\label{alg:floyd-war}
\end{algorithm}
\subsection{Eigenvector centrality}
% Katz
% Pagerank
% Newman's leading eigenvector method
