\section{Data Collection}

We use the USPTO patent grant full text dataset from January 1995 to December 
2013.  The dataset includes patent number, series code and application number,
type of patent, filing date, title, issue date, inventor information, assignee
name at time of issue, foreign priority information, related US patent
documents, classification information, US and foreign references, attorney,
agent or firm/legal representative, Patent Cooperation Treaty (PCT)
information, abstract, specification, and claims for each patent. We consider
only the following fields from the dataset for our study: patent number, issue
date, inventor name, inventor address, assignee name at time of issue, assignee address, US
references. 


\subsection{Pre-processing}

\begin{itemize}
\squish
\item {\em Collection \& Parsing:} We download the patent files from year 2005 to 2013 from the Google's portal for USPTO bulk patent download~\cite{usptodb}. These files are in various XML formats between v4.0 to v4.4. For the grant data prior to 2005, we use the truncated version from the Harvard DVN database~\cite{dvn}. Then we interpret the structured XML data, read it into python dictionaries and insert the compiled records into our SQLite database. We use the existing tools available from XML parsing and processing written in Python~\cite{newparser, formattingpatentdata, fungpaper}. 

\item {\em Disambiguation:} We run the author and organization disambiguation algorithms on this dataset, to cluster the inventors and organizations. Each unique entity is assigned a new internal ID, which we use for our graphs. The information about the disambiguated records is incorporated in the database. 

\item {\em Consolidation and Graph Construction:} 
We consolidate all the datasets together in our SQLite database, and generate the specifics views of data required for constructing the graphs for our further study.
% Finally, we consolidate this data with the pre-processed patent data for years 1975 to 2010 from Harvard Dataverse Network~\cite{}. 
\end{itemize}

Figure~\ref{process} summarizes the data collection, parsing and disambiguation phases we employ in our 
In summary, we extract the following fields from each patent that we parse :

\begin{itemize}
\squish
\item {\em Attributes for co-inventor relationship}:
Inventor name, inventor address, assignee name, assignee address, year of patent grant.

\item {\em Attributes for citations}:
Patent ID, name and address of all the inventors and assignees, year of patent grant, all the patents who cites this patent.
\end{itemize}


\subsection{Author \& Organization Disambiguation}

Apart from the primary dataset from USPTO, we use secondary data sets which are necessary for the disambiguation. Specifically, we use the NBER patent database which contains patents granted from 1975-1999~\cite{NBER}, Micropaten~\cite{micropatent}, USPTO CASSIS dataset for patent classification, National Geospatial-Intelligence Agency and US Board Geographic Names data sets~\cite{geocoding, geotable}. The secondary datasets are purely used for disambiguation and is not used for our main evaluation. These data sets are implicitly used for by the disambiguation algorithm available from ~\cite{disambiguation}.

\begin{figure}[H]
		  \centering	
          \includegraphics[scale=0.5]{../figures/process.pdf}
          \label{process}
          \caption{Overview of data collection and pre-processing steps to generate the co-inventorship and citation graphs.}
\end{figure}


\paragraph{Author Disambiguation Algorithm.}

Patent dataset is notoriously well known for disambiguation, since the patent office does not enforce uniqueness of names both for the inventor and the assignee organization. Thus, it is difficult to identify whether similar names correspond to a single inventor (e.g., John Doe and John S. Doe). This problem exacerbates in studies which are sensitive to the uniqueness of these entities.
For our study we piggyback on existing algorithm proposed by Lai \etal, and consider first name, last name, state and country and organization name for disambiguation.
Here, we briefly summarize the main insights used in this algorithm. The exact details are available at ~\cite{disambiguation}. 

Ideally, we would like to do an exhaustive pair-wise comparison of inventor-patent pair in dataset to check if they match or not. However, such search is of quadratic order and will incur 32 trillion comparisons for a dataset of 8 million records. 
To circumvent this challenge, the algorithm devices a cleaver heuristic called {\em blocking}. 
It first partitions the whole database into blocks which comprise of small groups of patent records which are more likely to be match. Thus, all the similar names (with small edit distance, same first name, last name, etc.) are 
analyzed independently of the rest of the records, so as to accelerate the process. Due to this, the disambiguation problem boils down to a classification problem --- does. It can be addressed with fair precision using the standard Naive Bayes classifier. 
It uses a trained probabilistic model which assumes multidimensional data and provides natural likelyhood-based framework for clustering. Further, the training is done via automatically generated training sets which are tailored to have highly probable matches and non-matches of samples. Further, the model is trained on intentionally generic predictive features such as relation between first name, last name, co-authors, technology class, location co-ordinates, assignee etc. 

\paragraph{Organization Disambiguation.}
We plan to use the algorithm by Fierro \etal for assignee disambiguation in our next phase of evaluation~\cite{newdisambiguation}.




\subsection{Data Consolidation \& Graph Construction}

We construct two graphs after the disambiguation phase is complete. 
The first graph is for the co-inventor network, where a vertex is an inventor, while an edge represents that two inventors have a joint patent. The second graph is for the citation network, where the vertices can be inventors or patents and the edges are citations (See Section~\ref{sec:model} for details).
We extract this information from our SQLite database, and generate a GraphML file for this network.
Table~\ref{listing} shows an example entry from GraphML for this network.
We report the statistics about the graph size and properties in Section~\cite{sec:eval}.

\begin{table*}[h] 
  \centering
  \begin{tabular}{@{}c@{}} 

  \begin{minipage}{0.25\linewidth}

\begin{lstlisting}[]
<node id="n196819">
  <data key="Loc">BOZEMAN-MT-US</data>
  <data key="Name">BERG, LLOYD</data>
  <data key="id">04292142-1</data>
  <data key="Patents">247</data>
</node>
\end{lstlisting}

  \end{minipage}
  \hspace{0.05\linewidth}
  \begin{minipage}{0.3\linewidth}

\begin{lstlisting}[]
<node id="n471405">
  <data key="Loc">BOZEMAN-MT-US</data>
  <data key="Name">EDISON, THOMAS A</data>
  <data key="id">05147512-2</data>
  <data key="Patents">1</data>
</node>
\end{lstlisting}

  \end{minipage}
  \hspace{0.05\linewidth}
  \begin{minipage}{0.3\linewidth}

\begin{lstlisting}[]
<edge source="n196819" target="n471405">
  <data key="tId">05147512-2</data>
  <data key="hId">04292142-1</data>
  <data key="AppYear">1991</data>
  <data key="Weight">1</data>
</edge>



\end{lstlisting}

  \end{minipage}
  
  \end{tabular}

\label{listing}
\caption{\footnotesize Snippet of entries from GraphXML file. Shows the nodes for Lloyd Berg and Thomas Edison and the corresponding edge between them.}
\end{table*}